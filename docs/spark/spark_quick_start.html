
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Spark Quick Start · bigdata-introduction</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="pruce">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-tbfed-pagefooter/footer.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-donate/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-multipart/multipart.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="spark_running.html" />
    
    
    <link rel="prev" href="../" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                        <b>1.1.</b>
                    
                    Introduction
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Spark</li>
        
        
    
        <li class="chapter active" data-level="2.1" data-path="spark_quick_start.html">
            
                <a href="spark_quick_start.html">
            
                    
                        <b>2.1.</b>
                    
                    Spark Quick Start
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="spark_running.html">
            
                <a href="spark_running.html">
            
                    
                        <b>2.2.</b>
                    
                    Spark Running
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="spark_streaming_quick_start.html">
            
                <a href="spark_streaming_quick_start.html">
            
                    
                        <b>2.3.</b>
                    
                    Spark Streaming Quick Start
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="spark_important.html">
            
                <a href="spark_important.html">
            
                    
                        <b>2.4.</b>
                    
                    Spark划重点
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Hadoop</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../hadoop/hadoop_deploy_linux.html">
            
                <a href="../hadoop/hadoop_deploy_linux.html">
            
                    
                        <b>3.1.</b>
                    
                    在Ubuntu_Centos上部署Hadoop
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="../hadoop/hadoop_deploy_mac.html">
            
                <a href="../hadoop/hadoop_deploy_mac.html">
            
                    
                        <b>3.2.</b>
                    
                    在Mac OS上部署Hadoop
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Hive</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="../hive/hive_quick_start.html">
            
                <a href="../hive/hive_quick_start.html">
            
                    
                        <b>4.1.</b>
                    
                    Hive Quick Start
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="../hive/hive_join.html">
            
                <a href="../hive/hive_join.html">
            
                    
                        <b>4.2.</b>
                    
                    Join解析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="../hive/hive_window_function.html">
            
                <a href="../hive/hive_window_function.html">
            
                    
                        <b>4.3.</b>
                    
                    分析窗口函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="../hive/hive_optimize.html">
            
                <a href="../hive/hive_optimize.html">
            
                    
                        <b>4.4.</b>
                    
                    SQL优化
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Kafka</li>
        
        
    
        <li class="chapter " data-level="5.1" data-path="../kafka/kafka_quick_start.html">
            
                <a href="../kafka/kafka_quick_start.html">
            
                    
                        <b>5.1.</b>
                    
                    Kafka Quick Start
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Flume</li>
        
        
    
        <li class="chapter " data-level="6.1" data-path="../flume/flume_quick_start.html">
            
                <a href="../flume/flume_quick_start.html">
            
                    
                        <b>6.1.</b>
                    
                    Flume Quick Start
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Zookeeper</li>
        
        
    
        <li class="chapter " data-level="7.1" data-path="../zookeeper/zookeeper_quick_start.html">
            
                <a href="../zookeeper/zookeeper_quick_start.html">
            
                    
                        <b>7.1.</b>
                    
                    Zookeeper Quick Start
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">Thanks</li>
        
        
    
        <li class="chapter " data-level="8.1" data-path="../thanks.html">
            
                <a href="../thanks.html">
            
                    
                        <b>8.1.</b>
                    
                    感谢&参考文章
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Spark Quick Start</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="spark-quick-start">Spark Quick Start</h1>
<h3 id="&#x4E00;&#x3001;&#x5B89;&#x88C5;">&#x4E00;&#x3001;&#x5B89;&#x88C5;</h3>
<p><a href="http://spark.apache.org/" target="_blank">spark&#x4E0B;&#x8F7D;&amp;&#x89E3;&#x538B;</a></p>
<p><a href="http://spark.apache.org/docs/latest/quick-start.html" target="_blank">Quick start</a></p>
<p><a href="http://spark.apache.org/docs/latest/" target="_blank">Spark Overview</a></p>
<p><a href="http://spark.apache.org/docs/latest/programming-guide.html#transformations" target="_blank">Spark Programming Guide</a></p>
<p><a href="http://spark.apache.org/docs/latest/running-on-yarn.html" target="_blank">Running Spark on YARN</a></p>
<h3 id="&#x4E8C;&#x3001;scala-shell">&#x4E8C;&#x3001;scala shell</h3>
<pre><code class="lang-scala">./bin/spark-shell

scala&gt; <span class="hljs-keyword">val</span> lines = sc.textFile(<span class="hljs-string">&quot;/Users/huanghaifeng/Documents/study/spark/derby.log&quot;</span>)
lines: org.apache.spark.rdd.<span class="hljs-type">RDD</span>[<span class="hljs-type">String</span>] = /<span class="hljs-type">Users</span>/huanghaifeng/<span class="hljs-type">Documents</span>/spark/derby.log <span class="hljs-type">MapPartitionsRDD</span>[<span class="hljs-number">1</span>] at textFile at &lt;console&gt;:<span class="hljs-number">27</span>

scala&gt; lines.count()
res4: <span class="hljs-type">Long</span> = <span class="hljs-number">13</span>

scala&gt; lines.first()

scala&gt; <span class="hljs-keyword">val</span> sparkLine = lines.filter(line =&gt; line.contains(<span class="hljs-string">&quot;spark&quot;</span>))
sparkLine: org.apache.spark.rdd.<span class="hljs-type">RDD</span>[<span class="hljs-type">String</span>] = <span class="hljs-type">MapPartitionsRDD</span>[<span class="hljs-number">2</span>] at filter at &lt;console&gt;:<span class="hljs-number">29</span>

scala&gt; sparkLine.first()
res7: <span class="hljs-type">String</span> = <span class="hljs-string">&quot;on database directory /Users/huanghaifeng/Documents/spark/metastore_db with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@6bc8d8bd &quot;</span>

scala&gt; sparkLine.count()
res8: <span class="hljs-type">Long</span> = <span class="hljs-number">3</span>
</code></pre>
<h3 id="&#x4E09;&#x3001;&#x6838;&#x5FC3;&#x6982;&#x5FF5;&#x4ECB;&#x7ECD;">&#x4E09;&#x3001;&#x6838;&#x5FC3;&#x6982;&#x5FF5;&#x4ECB;&#x7ECD;</h3>
<h4 id="31-&#x5B8F;&#x89C2;overview">3.1 &#x5B8F;&#x89C2;overview</h4>
<ul>
<li><p>Speed
Run programs up to 100x faster than Hadoop MapReduce in memory, or 10x faster on disk.</p>
</li>
<li><p>Ease of Use
Write applications quickly in Java, Scala, Python, R.</p>
</li>
<li><p>Generality
Combine SQL, streaming, and complex analytics. 
<img src="../pic/spark/spark_overview.png" alt="overview"></p>
</li>
<li><p>Runs Everywhere 
Spark runs on Hadoop, Mesos, standalone, or in the cloud. It can access diverse data sources including HDFS, Cassandra, HBase, and S3. </p>
<p><a href="http://spark.apache.org/" target="_blank">&#x5F15;&#x7528;&#x6E90;&#x81EA;Spark&#x5B98;&#x7F51;</a></p>
</li>
</ul>
<h4 id="32-spark&#x77E5;&#x8BC6;&#x70B9;">3.2 spark&#x77E5;&#x8BC6;&#x70B9;</h4>
<ul>
<li>Spark Core Api</li>
<li>Spark SQL </li>
<li>Spark Streaming &#x6D41;&#x5F0F;&#x8BA1;&#x7B97;</li>
<li>Spark MLib &#x673A;&#x5668;&#x5B66;&#x4E60;</li>
<li>Spark GraphX &#x5E76;&#x884C;&#x7684;&#x56FE;&#x8BA1;&#x7B97;</li>
<li>Spark&#x7684;&#x96C6;&#x7FA4;&#x7BA1;&#x7406;&#x5668;&#xFF08;YARN&#x3001;Mesos&#x3001;&#x81EA;&#x5E26;&#x7684;&#x72EC;&#x7ACB;&#x8C03;&#x5EA6;&#x5668;&#xFF09;</li>
</ul>
<h4 id="33-&#x4EFB;&#x52A1;&#x8FD0;&#x884C;&#x8FC7;&#x7A0B;">3.3 &#x4EFB;&#x52A1;&#x8FD0;&#x884C;&#x8FC7;&#x7A0B;</h4>
<p>&#x4E00;&#x4E2A;Spark&#x5E94;&#x7528; --&gt; &#x4E00;&#x4E2A;&#x9A71;&#x52A8;&#x5668;(driver program)&#x8282;&#x70B9; --&gt; &#x591A;&#x4E2A;&#x5DE5;&#x4F5C;&#x8282;&#x70B9;(worker node)<br>&#x4E00;&#x4E2A;&#x5DE5;&#x4F5C;&#x8282;&#x70B9; --&gt; &#x4E00;&#x4E2A;&#x6267;&#x884C;&#x5668;(executor) --&gt; &#x591A;&#x4E2A;&#x5E76;&#x884C;&#x4EFB;&#x52A1;(task)</p>
<p><img src="../pic/spark/cluster-overview.png" alt="cluster-overview"></p>
<h4 id="34-&#x51E0;&#x4E2A;&#x4EFB;&#x52A1;&#x6982;&#x5FF5;&#x7684;&#x533A;&#x5206;">3.4 &#x51E0;&#x4E2A;&#x4EFB;&#x52A1;&#x6982;&#x5FF5;&#x7684;&#x533A;&#x5206;</h4>
<p><a href="http://spark.apache.org/docs/latest/cluster-overview.html" target="_blank">http://spark.apache.org/docs/latest/cluster-overview.html</a></p>
<ul>
<li>job &#x4E00;&#x7CFB;&#x5217;stage&#x7EC4;&#x6210;&#x4E00;&#x4E2A;job&#xFF0C;&#x4E00;&#x4E2A;&#x884C;&#x52A8;&#x5C31;&#x662F;&#x4E00;&#x4E2A;job</li>
<li>stage &#x4E00;&#x4E2A;job&#x53EF;&#x4EE5;&#x5206;&#x4E3A;&#x591A;&#x4E2A;stage&#xFF0C; stage&#x5212;&#x5206;&#x7684;&#x6761;&#x4EF6;&#xFF0C;shuffle&#x6216;&#x8005;&#x884C;&#x52A8;&#x64CD;&#x4F5C;</li>
<li>task executor&#x4E0A;&#x7684;&#x6700;&#x5C0F;&#x4EFB;&#x52A1;&#x5355;&#x5143;&#x79F0;&#x4E4B;&#x4E3A;task&#xFF0C;task&#x662F;&#x5E76;&#x884C;&#x7684;&#xFF0C;&#x5355;&#x4E2A;shuffle&#x6839;&#x636E;partition&#x6570;&#x5212;&#x5206;&#x6210;n&#x4E2A;tasks</li>
</ul>
<table>
<thead>
<tr>
<th>Term</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>Application</td>
<td>User program built on Spark. Consists of a driver program and executors on the cluster.</td>
</tr>
<tr>
<td>Application jar</td>
<td>A jar containing the user&apos;s Spark application. In some cases users will want to create an &quot;uber jar&quot; containing their application along with its dependencies. The user&apos;s jar should never include Hadoop or Spark libraries, however, these will be added at runtime.</td>
</tr>
<tr>
<td>Driver program</td>
<td>The process running the main() function of the application and creating the SparkContext</td>
</tr>
<tr>
<td>Cluster manager</td>
<td>An external service for acquiring resources on the cluster (e.g. standalone manager, Mesos, YARN)</td>
</tr>
<tr>
<td>Deploy mode</td>
<td>Distinguishes where the driver process runs. In &quot;cluster&quot; mode, the framework launches the driver inside of the cluster. In &quot;client&quot; mode, the submitter launches the driver outside of the cluster.</td>
</tr>
<tr>
<td>Worker node</td>
<td>Any node that can run application code in the cluster</td>
</tr>
<tr>
<td>Executor</td>
<td>A process launched for an application on a worker node, that runs tasks and keeps data in memory or disk storage across them. Each application has its own executors.</td>
</tr>
<tr>
<td>Task</td>
<td>A unit of work that will be sent to one executor</td>
</tr>
<tr>
<td>Job</td>
<td>A parallel computation consisting of multiple tasks that gets spawned in response to a Spark action (e.g. save, collect); you&apos;ll see this term used in the driver&apos;s logs.</td>
</tr>
<tr>
<td>Stage</td>
<td>Each job gets divided into smaller sets of tasks called stages that depend on each other (similar to the map and reduce stages in MapReduce); you&apos;ll see this term used in the driver&apos;s logs.</td>
</tr>
</tbody>
</table>
<h3 id="&#x56DB;&#x3001;spark-core&#x539F;&#x7406;&#x89E3;&#x6790;">&#x56DB;&#x3001;Spark Core&#x539F;&#x7406;&#x89E3;&#x6790;</h3>
<h4 id="41-&#x67B6;&#x6784;">4.1 &#x67B6;&#x6784;</h4>
<ul>
<li>Spark&#x96C6;&#x7FA4;&#x91C7;&#x7528;&#x7684;&#x662F;&#x5178;&#x578B;&#x7684;&#x4E3B; / &#x4ECE;&#x7ED3;&#x6784;</li>
<li>&#x4E00;&#x4E2A;Spark&#x5E94;&#x7528;(application) = &#x4E00;&#x4E2A;&#x4E2D;&#x592E;&#x534F;&#x8C03;&#x9A71;&#x52A8;&#x5668;(Driver)&#x8282;&#x70B9; + &#x591A;&#x4E2A;&#x6267;&#x884C;&#x4EFB;&#x52A1;&#x7684;&#x6267;&#x884C;&#x5668;(Executor)&#x8282;&#x70B9;&#xFF1B;</li>
<li>&#x3010;Executor&#x3011;&#x8D1F;&#x8D23;&#x5E76;&#x884C;&#x7684;&#x6267;&#x884C;&#x4EFB;&#x52A1;&#xFF08;task&#xFF09;&#x3001;&#x5B58;&#x50A8;&#x5FC5;&#x8981;&#x7684;RDD&#x6570;&#x636E;  </li>
<li>&#x3010;Driver&#x3011;&#x8D1F;&#x8D23;&#x4EFB;&#x52A1;&#x62C6;&#x5206;&#x3001;&#x4EFB;&#x52A1;&#x8C03;&#x5EA6;</li>
<li>&#x7A0B;&#x5E8F;&#x4E4B;&#x95F4;&#x7684;RDD&#x53D8;&#x6362;&#x5173;&#x7CFB;&#x7EC4;&#x6210;&#x4E86;&#x4E00;&#x5F20;&#x903B;&#x8F91;&#x4E0A;&#x7684;DAG&#xFF0C;&#x7A0B;&#x5E8F;&#x8FD0;&#x884C;&#x65F6;&#x903B;&#x8F91;&#x56FE;&#x5C06;&#x8F6C;&#x6362;&#x4E3A;&#x7269;&#x7406;&#x6267;&#x884C;&#x8FC7;&#x7A0B;&#xFF0C;Driver&#x5728;&#x5BF9;&#x4EFB;&#x52A1;&#x5212;&#x5206;&#x7684;&#x65F6;&#x5019;&#x4F1A;&#x5C06;<strong>&#x8FDE;&#x7EED;&#x7684;&#x6620;&#x5C04;&#x8F6C;&#x4E3A;&#x6D41;&#x6C34;&#x7EBF;</strong>&#xFF0C;&#x5C06;&#x591A;&#x4E2A;&#x64CD;&#x4F5C;&#x5408;&#x5E76;&#x5230;&#x540C;&#x4E00;&#x4E2A;&#x6B65;&#x9AA4;&#xFF08;stage&#xFF09;&#x4E2D;&#x6765;&#xFF0C;&#x660E;&#x663E;&#x7684;&#x4F8B;&#x5B50;</li>
</ul>
<pre><code class="lang-scala"><span class="hljs-keyword">val</span> local_lines = sc.textFile(<span class="hljs-string">&quot;XXX&quot;</span>)
local_lines.first()
#&#x8FDE;&#x7EED;&#x8D77;&#x6765;&#x6267;&#x884C;&#x540E;&#x53EA;&#x9700;&#x8981;&#x52A0;&#x8F7D;&#x6587;&#x4EF6;&#x7684;&#x7B2C;&#x4E00;&#x884C;
</code></pre>
<ul>
<li>Application -&gt; Jobs -&gt; stages -&gt; tasks</li>
</ul>
<pre><code class="lang-scala"><span class="hljs-number">1</span>) <span class="hljs-keyword">val</span> local_lines = sc.textFile(<span class="hljs-string">&quot;XXX&quot;</span>)
<span class="hljs-number">1.2</span>) <span class="hljs-keyword">val</span> local_lines_1 = local_lines.map(xxx)
<span class="hljs-number">2</span>) <span class="hljs-keyword">val</span> local_lines_2 = sc.textFile(<span class="hljs-string">&quot;XXX&quot;</span>)
<span class="hljs-number">3</span>) println(local_lines_1.union(local_lines_2)) 

# <span class="hljs-number">3</span>)&#x662F;&#x4E00;&#x4E2A;job&#xFF0C;&#x53EF;&#x4EE5;&#x62C6;&#x5206;&#x4E3A;<span class="hljs-number">1</span>*&#xFF09;&#x3001;<span class="hljs-number">2</span>&#xFF09;&#x4E24;&#x4E2A;stage
# &#x6BCF;&#x4E2A;stage&#x53EF;&#x4EE5;&#x5206;&#x4E3A;&#x5E76;&#x884C;&#x7684;&#x591A;&#x4E2A;task
</code></pre>
<ul>
<li>&#x3010;&#x96C6;&#x7FA4;&#x7BA1;&#x7406;&#x5668;&#x3011;&#x542F;&#x52A8;&#x6267;&#x884C;&#x5668;&#x8282;&#x70B9;&#xFF0C;&#x67D0;&#x4E9B;&#x7279;&#x5B9A;&#x60C5;&#x51B5;(&#x6BD4;&#x5982;&#x3001;--deloy-mode=cluster)&#x4E0B;&#x624D;&#x4F1A;&#x9760;&#x96C6;&#x7FA4;&#x7BA1;&#x7406;&#x5668;&#x6765;&#x542F;&#x52A8;&#x9A71;&#x52A8;&#x5668;&#x8282;&#x70B9;&#x3002;&#x7A0B;&#x5E8F;&#x542F;&#x52A8;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x9A71;&#x52A8;&#x5668;&#x7A0B;&#x5E8F;&#x4E0E;&#x96C6;&#x7FA4;&#x7BA1;&#x7406;&#x5668;&#x901A;&#x4FE1;&#x7533;&#x8BF7;&#x8D44;&#x6E90;&#x542F;&#x52A8;&#x6267;&#x884C;&#x5668;&#x8282;&#x70B9;&#xFF1B;&#x7A0B;&#x5E8F;&#x7ED3;&#x675F;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x9A71;&#x52A8;&#x5668;&#x7A0B;&#x5E8F;&#x7EC8;&#x6B62;&#x6267;&#x884C;&#x5668;&#x8FC7;&#x7A0B;&#xFF0C;&#x5E76;&#x544A;&#x8BC9;&#x96C6;&#x7FA4;&#x7BA1;&#x7406;&#x5668;&#x91CA;&#x653E;&#x8D44;&#x6E90;</li>
<li>&#x96C6;&#x7FA4;&#x7BA1;&#x7406;&#x5668;&#x7684;&#x4E3B;&#x8282;&#x70B9;&#x3001;&#x4ECE;&#x8282;&#x70B9;&#x548C;Spark&#x7684;&#x9A71;&#x52A8;&#x5668;&#x3001;&#x6267;&#x884C;&#x5668;&#x8282;&#x70B9;&#x662F;&#x4E24;&#x4E2A;&#x7EF4;&#x5EA6;&#x7684;&#x6982;&#x5FF5;&#xFF1B;  <blockquote>
<p>&#x96C6;&#x7FA4;&#x7684;&#x4E3B;&#x4ECE;&#x8868;&#x793A;&#x96C6;&#x7FA4;&#x7684;&#x4E2D;&#x5FC3;&#x5316;&#x548C;&#x5206;&#x5E03;&#x5F0F;&#x7684;&#x90E8;&#x5206;<br>Spark&#x7684;&#x6267;&#x884C;&#x5668;&#x3001;&#x9A71;&#x52A8;&#x5668;&#x8282;&#x70B9;&#x63CF;&#x8FF0;&#x7684;&#x662F;&#x6267;&#x884C;Spark&#x7A0B;&#x5E8F;&#x7684;&#x4E24;&#x79CD;&#x8FDB;&#x7A0B;&#x7684;&#x8282;&#x70B9;<br>&#x4E8C;&#x8005;&#x6CA1;&#x6709;&#x5173;&#x8054;&#x6027;&#xFF0C;&#x6240;&#x4EE5;&#x5373;&#x4F7F;&#x5728;YARN&#x7684;&#x5DE5;&#x4F5C;&#x8282;&#x70B9;&#x4E0A;&#xFF0C;Spark&#x4E5F;&#x662F;&#x53EF;&#x4EE5;&#x8DD1;&#x6267;&#x884C;&#x5668;&#x548C;&#x9A71;&#x52A8;&#x5668;&#x8FDB;&#x7A0B;&#x7684;  </p>
</blockquote>
</li>
</ul>
<h4 id="42-dag&#x3001;jobs&#x3001;stage&#x3001;task&#x8BE6;&#x89E3;">4.2 DAG&#x3001;Jobs&#x3001;Stage&#x3001;Task&#x8BE6;&#x89E3;</h4>
<pre><code class="lang-scala"><span class="hljs-number">1</span>&#xFF09;<span class="hljs-keyword">val</span> input = sc.textFile(<span class="hljs-string">&quot;file:///tmp/input.txt&quot;</span>)
<span class="hljs-number">2</span>&#xFF09;<span class="hljs-keyword">val</span> tokenized = input.map(line =&gt; line.split(<span class="hljs-string">&quot; &quot;</span>)).filter(words =&gt; words.size&gt;<span class="hljs-number">0</span>)
<span class="hljs-number">3</span>&#xFF09;<span class="hljs-keyword">val</span> counts = tokenized.map(words =&gt; (words(<span class="hljs-number">0</span>), <span class="hljs-number">1</span>)).reduceByKey((a,b) =&gt; a+b)
<span class="hljs-number">4</span>&#xFF09;counts.collect()

# &#x6BCF;&#x4E00;&#x4E2A;<span class="hljs-type">RDD</span>&#x90FD;&#x8BB0;&#x5F55;&#x4E86;&#x7236;&#x8282;&#x70B9;&#x7684;&#x5173;&#x7CFB;
scala&gt; input.toDebugString
res82: <span class="hljs-type">String</span> =
(<span class="hljs-number">2</span>) file:<span class="hljs-comment">///tmp/input.txt MapPartitionsRDD[62] at textFile at &lt;console&gt;:27 []</span>
 |  file:<span class="hljs-comment">///tmp/input.txt HadoopRDD[61] at textFile at &lt;console&gt;:27 []</span>

scala&gt; tokenized.toDebugString
res83: <span class="hljs-type">String</span> =
(<span class="hljs-number">2</span>) <span class="hljs-type">MapPartitionsRDD</span>[<span class="hljs-number">64</span>] at filter at &lt;console&gt;:<span class="hljs-number">29</span> []
 |  <span class="hljs-type">MapPartitionsRDD</span>[<span class="hljs-number">63</span>] at map at &lt;console&gt;:<span class="hljs-number">29</span> []
 |  file:<span class="hljs-comment">///tmp/input.txt MapPartitionsRDD[62] at textFile at &lt;console&gt;:27 []</span>
 |  file:<span class="hljs-comment">///tmp/input.txt HadoopRDD[61] at textFile at &lt;console&gt;:27 []</span>

scala&gt; counts.toDebugString
res84: <span class="hljs-type">String</span> =
(<span class="hljs-number">2</span>) <span class="hljs-type">ShuffledRDD</span>[<span class="hljs-number">66</span>] at reduceByKey at &lt;console&gt;:<span class="hljs-number">31</span> []
 +-(<span class="hljs-number">2</span>) <span class="hljs-type">MapPartitionsRDD</span>[<span class="hljs-number">65</span>] at map at &lt;console&gt;:<span class="hljs-number">31</span> []
    |  <span class="hljs-type">MapPartitionsRDD</span>[<span class="hljs-number">64</span>] at filter at &lt;console&gt;:<span class="hljs-number">29</span> []
    |  <span class="hljs-type">MapPartitionsRDD</span>[<span class="hljs-number">63</span>] at map at &lt;console&gt;:<span class="hljs-number">29</span> []
    |  file:<span class="hljs-comment">///tmp/input.txt MapPartitionsRDD[62] at textFile at &lt;console&gt;:27 []</span>
    |  file:<span class="hljs-comment">///tmp/input.txt HadoopRDD[61] at textFile at &lt;console&gt;:27 []</span>

## &#x56E0;&#x4E3A;reduceByKey&#x662F;&#x4E00;&#x4E2A;&#x5BBD;&#x4F9D;&#x8D56;&#xFF0C;&#x5B58;&#x5728;shuffle&#x884C;&#x4E3A;
stage_1 : <span class="hljs-type">HadoopRDD</span> --&gt; <span class="hljs-type">MapPartitionsRDD</span> --&gt; map --&gt; filter --&gt; map
stage_2 : reduceByKey
</code></pre>
<ul>
<li>&#x4E00;&#x4E2A;job&#xFF08;counts.collect()&#xFF09;&#x88AB;&#x62C6;&#x6210;&#x4E86;&#x4E24;&#x4E2A;stages</li>
<li>&#x5728;&#x884C;&#x52A8;&#x64CD;&#x4F5C;&#x4E4B;&#x524D;&#xFF0C;&#x4E00;&#x5207;&#x90FD;&#x662F;&#x903B;&#x8F91;&#x7684;DAG&#xFF0C;&#x884C;&#x52A8;&#x64CD;&#x4F5C;&#x662F;&#x771F;&#x5B9E;&#x7684;&#x7269;&#x7406;&#x53D8;&#x5316;&#x53D1;&#x751F;&#x65F6;</li>
<li>&#x9A71;&#x52A8;&#x5668;&#x7A0B;&#x5E8F;&#x6267;&#x884C;&#x4E86;&#x201C;&#x6D41;&#x6C34;&#x7EBF;&#x64CD;&#x4F5C;&#x201D;&#xFF0C;&#x5C06;&#x591A;&#x4E2A;RDD&#x5408;&#x5E76;&#x8981;&#x4E00;&#x8D77;&#x6267;&#x884C;</li>
<li>&#x7CFB;&#x8C31;&#x56FE;&#x662F;&#x81EA;&#x4E0B;&#x800C;&#x4E0A;&#x7684;&#x67E5;&#x627E;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x5982;&#x679C;&#x4EFB;&#x4F55;&#x4E00;&#x4E2A;&#x7236;RDD&#x4E0A;&#x5DF2;&#x7ECF;&#x6709;&#x6570;&#x636E;&#x7F13;&#x5B58;&#xFF0C;&#x8FD9;&#x6761;&#x94FE;&#x8DEF;&#x90FD;&#x5C06;&#x5F97;&#x5230;&#x4F18;&#x5316;</li>
<li>Spark&#x7684;&#x6267;&#x884C;&#x6D41;&#x7A0B;&#xFF1A;&#x7528;&#x6237;&#x4EE3;&#x7801;&#x5B9A;&#x4E49;DAG - &#x884C;&#x52A8;&#x64CD;&#x4F5C;&#x5C06;DAG&#x8F6C;&#x8F6C;&#x4E49;&#x4E3A;&#x6267;&#x884C;&#x8BA1;&#x5212; - &#x4EFB;&#x52A1;&#x5728;&#x96C6;&#x7FA4;&#x4E2D;&#x8C03;&#x5EA6;&#x5E76;&#x6267;&#x884C;</li>
</ul>
<h4 id="43-&#x6267;&#x884C;&#x5668;&#x8282;&#x70B9;&#x5185;&#x5B58;&#x5206;&#x914D;">4.3 &#x6267;&#x884C;&#x5668;&#x8282;&#x70B9;&#x5185;&#x5B58;&#x5206;&#x914D;</h4>
<ul>
<li><p>&#x9ED8;&#x8BA4;60% RDD&#x5B58;&#x50A8;</p>
<pre><code class="lang-scala">cache()
persist()
</code></pre>
</li>
<li><p>&#x9ED8;&#x8BA4;20% &#x6570;&#x636E;&#x6E05;&#x6D17;&#x4E0E;&#x805A;&#x5408;<br>&#x7F13;&#x5B58;&#x6570;&#x636E;&#x6DF7;&#x6D17;&#x7684;&#x8F93;&#x51FA;&#x6570;&#x636E;&#xFF0C;&#x5B58;&#x50A8;&#x805A;&#x5408;&#x7684;&#x4E2D;&#x95F4;&#x7ED3;&#x679C;&#xFF0C;&#x901A;&#x8FC7;spark.shuffle.memoryFraction&#x6765;&#x9650;&#x5B9A;&#x5185;&#x5B58;&#x5360;&#x6BD4;</p>
</li>
<li><p>&#x9ED8;&#x8BA4;20% &#x7528;&#x6237;&#x4EE3;&#x7801;
&#x4E0E;&#x4EE3;&#x7801;&#x4E2D;&#x7684;&#x4E2D;&#x95F4;&#x6570;&#x636E;&#x5B58;&#x50A8;&#xFF0C;&#x6BD4;&#x5982;&#x521B;&#x5EFA;&#x6570;&#x7EC4;</p>
</li>
</ul>
<h4 id="44-&#x5BB9;&#x9519;&#x6027;">4.4 &#x5BB9;&#x9519;&#x6027;</h4>
<p>Spark&#x4F1A;&#x81EA;&#x52A8;&#x91CD;&#x65B0;&#x6267;&#x884C;&#x5931;&#x8D25;&#x7684; &#x6216; &#x8F83;&#x6162;&#x7684;&#x4EFB;&#x52A1;&#x6765;&#x5E94;&#x5BF9;&#x6709;&#x9519;&#x8BEF;&#x7684;&#x6216;&#x8005;&#x6BD4;&#x8F83;&#x6162;&#x7684;&#x673A;&#x5668;<br>Spark&#x8FD8;&#x53EF;&#x80FD;&#x4F1A;&#x5728;&#x4E00;&#x53F0;&#x65B0;&#x7684;&#x8282;&#x70B9;&#x4E0A;&#x6295;&#x673A;&#x7684;&#x6267;&#x884C;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x91CD;&#x590D;&#x4EFB;&#x52A1;&#xFF0C;&#x5982;&#x679C;&#x63D0;&#x524D;&#x7ED3;&#x675F;&#xFF0C;&#x5219;&#x63D0;&#x524D;&#x83B7;&#x53D6;&#x7ED3;&#x679C;&#xFF0C;&#x56E0;&#x6B64;&#x4E00;&#x4E2A;&#x65B9;&#x6CD5;&#x53EF;&#x80FD;&#x88AB;&#x6267;&#x884C;&#x591A;&#x6B21;  </p>
<h3 id="&#x4E94;&#x3001;rdd&#x7F16;&#x7A0B;">&#x4E94;&#x3001;RDD&#x7F16;&#x7A0B;</h3>
<h4 id="51-rdd&#x662F;&#x4EC0;&#x4E48;">5.1 RDD&#x662F;&#x4EC0;&#x4E48;</h4>
<p>RDD&#xFF08;&#x5F39;&#x6027;&#x5206;&#x5E03;&#x5F0F;&#x6570;&#x636E;&#x96C6;&#x3001;Resilient Distributed Dataset&#xFF09;&#x662F;Spark&#x7684;&#x6570;&#x636E;&#x7ED3;&#x6784;&#x3002;RDD&#x7684;&#x884C;&#x4E3A;&#x53EA;&#x5206;&#x4E3A;&#x4E09;&#x79CD;&#xFF1A;&#x521B;&#x5EFA;&#x3001;&#x8F6C;&#x5316;&#xFF08;&#x4EA7;&#x751F;&#x4E00;&#x4E2A;&#x65B0;&#x7684;RDD&#xFF09;&#x3001;&#x884C;&#x52A8;&#xFF08;&#x5BF9;&#x5F53;&#x524D;RDD&#x8FDB;&#x884C;&#x7EDF;&#x8BA1;&#xFF09;</p>
<h4 id="52-rdd&#x521B;&#x5EFA;">5.2 RDD&#x521B;&#x5EFA;</h4>
<pre><code class="lang-scala"><span class="hljs-keyword">val</span> local_lines = sc.textFile(<span class="hljs-string">&quot;file:///usr/local/opt/spark-latest-bin-hadoop2.4/README.md&quot;</span>)  
&#x6216;&#x8005;  
<span class="hljs-keyword">val</span> local_lines = sc.parallelize(<span class="hljs-type">List</span>(<span class="hljs-string">&quot;pandas&quot;</span>, <span class="hljs-string">&quot;i like pandas&quot;</span>)
</code></pre>
<h4 id="53-rdd&#x7684;&#x8F6C;&#x5316;">5.3 RDD&#x7684;&#x8F6C;&#x5316;</h4>
<p><img src="../pic/spark/rdd_transformation.png" alt="rdd_transformation">
<img src="../pic/spark/rdd_transformation_1.png" alt="rdd_transformation">
&#x7CFB;&#x8C31;&#x56FE;&#x8BB0;&#x5F55;&#x5404;&#x4E2A;RDD&#x4E4B;&#x95F4;&#x7684;&#x8F6C;&#x6362;&#x5173;&#x7CFB;</p>
<h5 id="531-&#x9488;&#x5BF9;&#x5404;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x8F6C;&#x5316;">5.3.1 &#x9488;&#x5BF9;&#x5404;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x8F6C;&#x5316;</h5>
<pre><code class="lang-scala"># map() &#x9488;&#x5BF9;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x4E00;&#x4E00;&#x5BF9;&#x5E94;&#x7684;&#x8F6C;&#x6362;
scala&gt; <span class="hljs-keyword">val</span> numbers = sc.parallelize(<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>));
scala&gt; numbers.map(x =&gt; x*x).collect().foreach(println)
<span class="hljs-number">1</span>
<span class="hljs-number">4</span>
<span class="hljs-number">9</span>
<span class="hljs-number">16</span>

# filter() &#x9488;&#x5BF9;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x8FC7;&#x6EE4;&#x9009;&#x62E9;
scala&gt; <span class="hljs-keyword">val</span> numbers = sc.parallelize(<span class="hljs-type">List</span>(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>));
scala&gt; numbers.filter(x =&gt; x&gt;<span class="hljs-number">2</span>).collect().foreach(println)
<span class="hljs-number">3</span>
<span class="hljs-number">4</span>

# flatmap() &#x5BF9;&#x6BCF;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x5904;&#x7406;&#x540E;&#x653E;&#x56DE;&#x540C;&#x4E00;&#x4E2A;&#x5927;&#x96C6;&#x5408;&#xFF0C;&#x5178;&#x578B;&#x7684;&#x4F8B;&#x5B50;&#xFF1A;split
scala&gt; <span class="hljs-keyword">val</span> strings = sc.parallelize(<span class="hljs-type">List</span>(<span class="hljs-string">&quot;huang#hai#feng&quot;</span>, <span class="hljs-string">&quot;zhong#guo&quot;</span>, <span class="hljs-string">&quot;huang#hai#feng&quot;</span>));
scala&gt; strings.flatMap(x =&gt; x.split(<span class="hljs-string">&quot;#&quot;</span>)).collect().foreach(println)
huang
hai
feng
zhong
guo
huang
hai
feng

# sample &#x91C7;&#x6837;&#xFF0C;
scala&gt; numbers.collect().foreach(println)
<span class="hljs-number">1</span>
<span class="hljs-number">2</span>
<span class="hljs-number">3</span>
<span class="hljs-number">4</span>
# &#x6BCF;&#x4E2A;&#x4F4D;&#x7F6E;&#x6309;&#x7167;&#x968F;&#x673A;&#x79CD;&#x5B50;&#xFF0C;&#x9009; or &#x4E0D;&#x9009;
scala&gt; numbers.sample(<span class="hljs-literal">false</span>, <span class="hljs-number">0.5</span>).collect().foreach(println)
<span class="hljs-number">1</span>
<span class="hljs-number">2</span>
<span class="hljs-number">4</span>
# &#x8FD9;&#x4E2A;<span class="hljs-literal">true</span>&#xFF0C;&#xFF0C; &#x5F85;&#x7406;&#x89E3;
scala&gt; numbers.sample(<span class="hljs-literal">true</span>, <span class="hljs-number">0.5</span>).collect().foreach(println)
<span class="hljs-number">2</span>
<span class="hljs-number">3</span>
<span class="hljs-number">3</span>
<span class="hljs-number">4</span>
</code></pre>
<h5 id="532-&#x4F2A;&#x96C6;&#x5408;&#x64CD;&#x4F5C;">5.3.2 &#x4F2A;&#x96C6;&#x5408;&#x64CD;&#x4F5C;</h5>
<pre><code class="lang-scala">scala&gt;  numbers.collect().foreach(println)
<span class="hljs-number">1</span>
<span class="hljs-number">2</span>
<span class="hljs-number">3</span>
<span class="hljs-number">4</span>
scala&gt;  numbers_1.collect().foreach(println)
<span class="hljs-number">3</span>
<span class="hljs-number">4</span>
<span class="hljs-number">5</span>
<span class="hljs-number">6</span>
# union &#x5E76;&#x96C6;&#xFF0C;&#x5141;&#x8BB8;&#x91CD;&#x590D;&#x5143;&#x7D20;
scala&gt; numbers.union(numbers_1).collect().foreach(println)
<span class="hljs-number">1</span>
<span class="hljs-number">2</span>
<span class="hljs-number">3</span>
<span class="hljs-number">4</span>
<span class="hljs-number">3</span>
<span class="hljs-number">4</span>
<span class="hljs-number">5</span>
<span class="hljs-number">6</span>
scala&gt; numbers.union(numbers_1).distinct().collect().foreach(println)
<span class="hljs-number">4</span>
<span class="hljs-number">1</span>
<span class="hljs-number">5</span>
<span class="hljs-number">6</span>
<span class="hljs-number">2</span>
<span class="hljs-number">3</span>

# intersection&#x4EA4;&#x96C6; 
scala&gt; numbers.intersection(numbers_1).collect().foreach(println)
<span class="hljs-number">4</span>
<span class="hljs-number">3</span>

# subtract&#x5DEE;&#x96C6;
scala&gt; numbers.subtract(numbers_1).collect().foreach(println)
<span class="hljs-number">2</span>
<span class="hljs-number">1</span>

# cartesian&#x7B1B;&#x5361;&#x5C14;&#x4E58;&#x79EF;
scala&gt; numbers.cartesian(numbers_1).collect().foreach(println)
(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>)
(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>)
(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)
(<span class="hljs-number">2</span>,<span class="hljs-number">4</span>)
(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>)
(<span class="hljs-number">1</span>,<span class="hljs-number">6</span>)
(<span class="hljs-number">2</span>,<span class="hljs-number">5</span>)
(<span class="hljs-number">2</span>,<span class="hljs-number">6</span>)
(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>)
(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)
(<span class="hljs-number">4</span>,<span class="hljs-number">3</span>)
(<span class="hljs-number">4</span>,<span class="hljs-number">4</span>)
(<span class="hljs-number">3</span>,<span class="hljs-number">5</span>)
(<span class="hljs-number">3</span>,<span class="hljs-number">6</span>)
(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>)
(<span class="hljs-number">4</span>,<span class="hljs-number">6</span>)
</code></pre>
<h4 id="54-rdd&#x7684;&#x884C;&#x52A8;">5.4 RDD&#x7684;&#x884C;&#x52A8;</h4>
<p><img src="../pic/spark/rdd_action.png" alt="rdd_action"></p>
<pre><code class="lang-scala"># reduce
scala&gt; numbers.reduce((x, y) =&gt; x*y)
res102: <span class="hljs-type">Int</span> = <span class="hljs-number">24</span>

# countByValue word count&#x5DF2;&#x5B9E;&#x73B0;
scala&gt; numbers.countByValue()
res104: scala.collection.<span class="hljs-type">Map</span>[<span class="hljs-type">Int</span>,<span class="hljs-type">Long</span>] = <span class="hljs-type">Map</span>(<span class="hljs-number">4</span> -&gt; <span class="hljs-number">1</span>, <span class="hljs-number">2</span> -&gt; <span class="hljs-number">1</span>, <span class="hljs-number">1</span> -&gt; <span class="hljs-number">1</span>, <span class="hljs-number">3</span> -&gt; <span class="hljs-number">1</span>)

# fold &#x9700;&#x8981;&#x4F20;&#x5165;&#x4E00;&#x4E2A;&#x521D;&#x59CB;&#x7684;&#x5355;&#x5143;&#x503C; &#x52A0;&#x6CD5;&#x662F;<span class="hljs-number">0</span> &#x4E58;&#x6CD5;&#x662F;<span class="hljs-number">1</span>
scala&gt; numbers.fold(<span class="hljs-number">1</span>)((x, y) =&gt; x*y)
res103: <span class="hljs-type">Int</span> = <span class="hljs-number">24</span>

# aggregate &#x6C42;&#x5E73;&#x5747;&#x6570;
scala&gt; <span class="hljs-keyword">val</span> numbers = sc.parallelize(<span class="hljs-type">List</span>(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>))
numbers: org.apache.spark.rdd.<span class="hljs-type">RDD</span>[<span class="hljs-type">Int</span>] = <span class="hljs-type">ParallelCollectionRDD</span>[<span class="hljs-number">0</span>] at parallelize at &lt;console&gt;:<span class="hljs-number">27</span>

#numbers.aggregate((<span class="hljs-number">0</span>,<span class="hljs-number">0</span>))(
#  ((x, value) =&gt; (x._1 + value, x._2 + <span class="hljs-number">1</span>)),
#  ((x1, x2) =&gt; (x1._1+x2._1, x1._2+x2._2))
#  )
scala&gt; numbers.aggregate((<span class="hljs-number">0</span>,<span class="hljs-number">0</span>))(((x, value) =&gt; (x._1 + value, x._2 + <span class="hljs-number">1</span>)), ((x1, x2) =&gt; (x1._1+x2._1, x1._2+x2._2)))
res0: (<span class="hljs-type">Int</span>, <span class="hljs-type">Int</span>) = (<span class="hljs-number">18</span>,<span class="hljs-number">4</span>)

scala&gt; res0._1/res0._2.toDouble
res1: <span class="hljs-type">Double</span> = <span class="hljs-number">4.5</span>
</code></pre>
<h4 id="55-rdd&#x7684;&#x6253;&#x5370;">5.5 RDD&#x7684;&#x6253;&#x5370;</h4>
<ul>
<li>take(n) &#x5206;&#x533A;&#x5C31;&#x8FD1;&#x539F;&#x5219;&#x51FA;<pre><code class="lang-scala">scala&gt; numbers.take(<span class="hljs-number">2</span>).foreach(println)
<span class="hljs-number">1</span>
<span class="hljs-number">2</span>
</code></pre>
</li>
<li>top(n)<pre><code class="lang-scala">scala&gt; numbers.top(<span class="hljs-number">2</span>).foreach(println) &#x6309;&#x7167;&#x6570;&#x636E;&#x96C6;&#x5408;&#x81EA;&#x5DF1;&#x7684;&#x987A;&#x5E8F;&#x51FA;
<span class="hljs-number">4</span>
<span class="hljs-number">3</span>
</code></pre>
</li>
<li>sample(bWithReplacement, dFraction, seed) &#x4E22;&#x9AB0;&#x5B50;&#x53D6;&#x6837;<pre><code class="lang-scala">scala&gt; numbers.sample(<span class="hljs-literal">false</span>, <span class="hljs-number">0.3</span>).foreach(println)
<span class="hljs-number">3</span>
<span class="hljs-number">4</span>
<span class="hljs-number">2</span>
</code></pre>
</li>
<li>takeSample(bWithReplacement, n, seed) &#x968F;&#x673A;&#x53D6;&#x6837;n&#x4E2A;<pre><code class="lang-scala">scala&gt; numbers.takeSample(<span class="hljs-literal">false</span>, <span class="hljs-number">3</span>).foreach(println)
<span class="hljs-number">4</span>
<span class="hljs-number">3</span>
<span class="hljs-number">1</span>
</code></pre>
</li>
<li>collect() &#x5168;&#x8FD4;&#x56DE;<pre><code class="lang-scala">scala&gt; numbers.collect().foreach(println)
<span class="hljs-number">1</span>
<span class="hljs-number">2</span>
<span class="hljs-number">3</span>
<span class="hljs-number">4</span>
scala&gt; numbers.collect().mkString(<span class="hljs-string">&quot;,&quot;</span>)
res2: <span class="hljs-type">String</span> = <span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>
</code></pre>
</li>
</ul>
<h4 id="56-&#x6301;&#x4E45;&#x5316;&#x7684;&#x51E0;&#x79CD;&#x7C7B;&#x578B;">5.6 &#x6301;&#x4E45;&#x5316;&#x7684;&#x51E0;&#x79CD;&#x7C7B;&#x578B;</h4>
<table>
<thead>
<tr>
<th>&#x7EA7;&#x522B;</th>
<th>&#x4F7F;&#x7528;&#x7684;&#x7A7A;&#x95F4;</th>
<th>CPU&#x65F6;&#x95F4;</th>
<th>&#x662F;&#x5426;&#x5728;&#x5185;&#x5B58;&#x4E2D;</th>
<th>&#x662F;&#x5426;&#x5728;&#x78C1;&#x76D8;&#x4E0A;</th>
<th>&#x5907;&#x6CE8;</th>
</tr>
</thead>
<tbody>
<tr>
<td>NONE</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>DISK_ONLY</td>
<td>&#x4F4E;</td>
<td>&#x9AD8;</td>
<td>&#x5426;</td>
<td>&#x662F;</td>
<td></td>
</tr>
<tr>
<td>DISK_ONLY_2</td>
<td>&#x4F4E;</td>
<td>&#x9AD8;</td>
<td>&#x5426;</td>
<td>&#x662F;</td>
<td>&#x540C;&#x4E0A;&#x4E00;&#x4E2A;&#x7EA7;&#x522B;&#xFF0C;&#x4F46;&#x5B58;&#x4E86;&#x4E24;&#x4EFD;</td>
</tr>
<tr>
<td>MEMORY_ONLY</td>
<td>&#x9AD8;</td>
<td>&#x4F4E;</td>
<td>&#x662F;</td>
<td>&#x5426;</td>
<td></td>
</tr>
<tr>
<td>MEMORY_ONLY_2</td>
<td>&#x9AD8;</td>
<td>&#x4F4E;</td>
<td>&#x662F;</td>
<td>&#x5426;</td>
<td>&#x540C;&#x4E0A;&#x4E00;&#x4E2A;&#x7EA7;&#x522B;&#xFF0C;&#x4F46;&#x5B58;&#x4E86;&#x4E24;&#x4EFD;</td>
</tr>
<tr>
<td>MEMORY_ONLY_SER</td>
<td>&#x4F4E;</td>
<td>&#x9AD8;</td>
<td>&#x662F;</td>
<td>&#x5426;</td>
<td>ser&#x662F;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x610F;&#x601D;</td>
</tr>
<tr>
<td>MEMORY_ONLY_SER_2</td>
<td>&#x4F4E;</td>
<td>&#x9AD8;</td>
<td>&#x662F;</td>
<td>&#x5426;</td>
<td>&#x540C;&#x4E0A;&#x4E00;&#x4E2A;&#x7EA7;&#x522B;&#xFF0C;&#x4F46;&#x5B58;&#x4E86;&#x4E24;&#x4EFD;</td>
</tr>
<tr>
<td>MEMORY_AND_DISK</td>
<td>&#x9AD8;</td>
<td>&#x4E2D;&#x7B49;</td>
<td>&#x90E8;&#x5206;</td>
<td>&#x90E8;&#x5206;</td>
<td>&#x5982;&#x679C;&#x5185;&#x5B58;&#x88C5;&#x4E0D;&#x4E0B;&#x4E86;&#xFF0C;&#x591A;&#x51FA;&#x4E86;&#x7684;&#x5199;&#x5230;&#x78C1;&#x76D8;</td>
</tr>
<tr>
<td>MEMORY_AND_DISK_2</td>
<td>&#x9AD8;</td>
<td>&#x4E2D;&#x7B49;</td>
<td>&#x90E8;&#x5206;</td>
<td>&#x90E8;&#x5206;</td>
<td>&#x540C;&#x4E0A;&#x4E00;&#x4E2A;&#x7EA7;&#x522B;&#xFF0C;&#x4F46;&#x5B58;&#x4E86;&#x4E24;&#x4EFD;</td>
</tr>
<tr>
<td>MEMORY_AND_DISK_SER</td>
<td>&#x4F4E;</td>
<td>&#x9AD8;</td>
<td>&#x90E8;&#x5206;</td>
<td>&#x90E8;&#x5206;</td>
<td>&#x5185;&#x5B58;&#x5B58;&#x4E0D;&#x4E0B;&#xFF0C;&#x591A;&#x51FA;&#x6765;&#x7684;&#x90E8;&#x5206;&#x5B58;&#x5230;&#x78C1;&#x76D8;&#xFF0C;&#x5E76;&#x5C06;&#x5E8F;&#x5217;&#x5316;&#x6570;&#x636E;&#x5199;&#x5165;&#x5185;&#x5B58;</td>
</tr>
<tr>
<td>MEMORY_AND_DISK_SER_2</td>
<td>&#x4F4E;</td>
<td>&#x9AD8;</td>
<td>&#x90E8;&#x5206;</td>
<td>&#x90E8;&#x5206;</td>
<td>&#x540C;&#x4E0A;&#x4E00;&#x4E2A;&#x7EA7;&#x522B;&#xFF0C;&#x4F46;&#x5B58;&#x4E86;&#x4E24;&#x4EFD;</td>
</tr>
<tr>
<td>OFF_HEAP</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>&#x5982;&#x679C;&#x5185;&#x5B58;&#x4F7F;&#x7528;&#x7684;&#x4E0D;&#x591F;&#x4E86;&#xFF0C; &#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x6700;&#x5C11;&#x4F7F;&#x7528;&#x539F;&#x5219;&#xFF08;LRU&#xFF09;&#x8FDB;&#x884C;&#x56DE;&#x6536;</li>
<li>Spark&#x8FD8;&#x63D0;&#x4F9B;&#x6709;unpersist()&#x65B9;&#x6CD5;&#x624B;&#x52A8;&#x91CA;&#x653E;&#x5185;&#x5B58;</li>
</ul>
<h3 id="&#x516D;&#x3001;pair-rdd&#x7F16;&#x7A0B;">&#x516D;&#x3001;Pair RDD&#x7F16;&#x7A0B;</h3>
<h4 id="61-&#x521B;&#x5EFA;pair-rdd">6.1 &#x521B;&#x5EFA;Pair RDD</h4>
<pre><code class="lang-scala">scala&gt; numbers.collect().mkString(<span class="hljs-string">&quot;,&quot;</span>)
res7: <span class="hljs-type">String</span> = <span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>

scala&gt; <span class="hljs-keyword">val</span> pairs = numbers.map(x =&gt; (x+<span class="hljs-number">1</span>, x*x))
pairs: org.apache.spark.rdd.<span class="hljs-type">RDD</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">Int</span>)] = <span class="hljs-type">MapPartitionsRDD</span>[<span class="hljs-number">1</span>] at map at &lt;console&gt;:<span class="hljs-number">29</span>

scala&gt; pairs.collect().mkString(<span class="hljs-string">&quot;,&quot;</span>)
res9: <span class="hljs-type">String</span> = (<span class="hljs-number">4</span>,<span class="hljs-number">9</span>),(<span class="hljs-number">5</span>,<span class="hljs-number">16</span>),(<span class="hljs-number">6</span>,<span class="hljs-number">25</span>),(<span class="hljs-number">7</span>,<span class="hljs-number">36</span>)

<span class="hljs-keyword">val</span> lines = sc.textFile(<span class="hljs-string">&quot;data.txt&quot;</span>)
<span class="hljs-keyword">val</span> pairs = lines.map(s =&gt; (s, <span class="hljs-number">1</span>))
<span class="hljs-keyword">val</span> counts = pairs.reduceByKey((a, b) =&gt; a + b)
</code></pre>
<h4 id="62-&#x8F6C;&#x5316;&#x64CD;&#x4F5C;">6.2 &#x8F6C;&#x5316;&#x64CD;&#x4F5C;</h4>
<p><img src="../pic/spark/prdd_transformation.png" alt="prdd_transformation">
<img src="../pic/spark/prdd_transformation_1.png" alt="prdd_transformation">
<img src="../pic/spark/prdd_transformation_2.png" alt="prdd_transformation"></p>
<pre><code class="lang-scala">scala&gt; <span class="hljs-keyword">val</span> pairs_1 = sc.parallelize(<span class="hljs-type">List</span>((<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), (<span class="hljs-number">3</span>, <span class="hljs-number">4</span>), (<span class="hljs-number">3</span>, <span class="hljs-number">6</span>)))
pairs_1: org.apache.spark.rdd.<span class="hljs-type">RDD</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">Int</span>)] = <span class="hljs-type">ParallelCollectionRDD</span>[<span class="hljs-number">3</span>] at parallelize at &lt;console&gt;:<span class="hljs-number">27</span>

scala&gt; pairs_1.collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res12: <span class="hljs-type">String</span> = (<span class="hljs-number">1</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">6</span>)

scala&gt; pairs_1.reduceByKey((x, y) =&gt; x+y).collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res13: <span class="hljs-type">String</span> = (<span class="hljs-number">1</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">10</span>)

scala&gt; pairs_1.groupByKey().collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res16: <span class="hljs-type">String</span> = (<span class="hljs-number">1</span>,<span class="hljs-type">CompactBuffer</span>(<span class="hljs-number">2</span>)),(<span class="hljs-number">3</span>,<span class="hljs-type">CompactBuffer</span>(<span class="hljs-number">4</span>, <span class="hljs-number">6</span>))

scala&gt; pairs_1.mapValues(x =&gt; x+<span class="hljs-number">10</span>).collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res17: <span class="hljs-type">String</span> = (<span class="hljs-number">1</span>,<span class="hljs-number">12</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">14</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">16</span>)

scala&gt; pairs_1.flatMapValues(x =&gt; (x to <span class="hljs-number">15</span>)).collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res19: <span class="hljs-type">String</span> = (<span class="hljs-number">1</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">6</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">7</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">8</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">9</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">11</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">12</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">13</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">14</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">15</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">5</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">6</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">7</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">8</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">9</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">10</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">11</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">12</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">13</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">14</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">15</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">6</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">7</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">8</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">9</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">10</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">11</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">12</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">13</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">14</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">15</span>)

scala&gt; pairs_1.keys.collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res24: <span class="hljs-type">String</span> = <span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>

scala&gt; pairs_1.values.collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res25: <span class="hljs-type">String</span> = <span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>

scala&gt; pairs_1.sortByKey().collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res28: <span class="hljs-type">String</span> = (<span class="hljs-number">1</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">6</span>)

scala&gt; pairs_1.sortByKey(<span class="hljs-literal">false</span>).collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res49: <span class="hljs-type">String</span> = (<span class="hljs-number">3</span>,<span class="hljs-number">4</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">6</span>),(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)

----------------------------

scala&gt; pairs_1.sortByKey().collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res28: <span class="hljs-type">String</span> = (<span class="hljs-number">1</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">6</span>)

scala&gt; <span class="hljs-keyword">val</span> pairs_2 = sc.parallelize(<span class="hljs-type">List</span>((<span class="hljs-number">3</span>, <span class="hljs-number">9</span>)))
pairs_2: org.apache.spark.rdd.<span class="hljs-type">RDD</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">Int</span>)] = <span class="hljs-type">ParallelCollectionRDD</span>[<span class="hljs-number">15</span>] at parallelize at &lt;console&gt;:<span class="hljs-number">27</span>

scala&gt; pairs_1.join(pairs_2).collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res31: <span class="hljs-type">String</span> = (<span class="hljs-number">3</span>,(<span class="hljs-number">4</span>,<span class="hljs-number">9</span>)),(<span class="hljs-number">3</span>,(<span class="hljs-number">6</span>,<span class="hljs-number">9</span>))

scala&gt; pairs_1.rightOuterJoin(pairs_2).collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res33: <span class="hljs-type">String</span> = (<span class="hljs-number">3</span>,(<span class="hljs-type">Some</span>(<span class="hljs-number">4</span>),<span class="hljs-number">9</span>)),(<span class="hljs-number">3</span>,(<span class="hljs-type">Some</span>(<span class="hljs-number">6</span>),<span class="hljs-number">9</span>))

scala&gt; pairs_1.leftOuterJoin(pairs_2).collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res34: <span class="hljs-type">String</span> = (<span class="hljs-number">1</span>,(<span class="hljs-number">2</span>,<span class="hljs-type">None</span>)),(<span class="hljs-number">3</span>,(<span class="hljs-number">4</span>,<span class="hljs-type">Some</span>(<span class="hljs-number">9</span>))),(<span class="hljs-number">3</span>,(<span class="hljs-number">6</span>,<span class="hljs-type">Some</span>(<span class="hljs-number">9</span>)))

scala&gt; pairs_1.cogroup(pairs_2).collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res35: <span class="hljs-type">String</span> = (<span class="hljs-number">1</span>,(<span class="hljs-type">CompactBuffer</span>(<span class="hljs-number">2</span>),<span class="hljs-type">CompactBuffer</span>())),(<span class="hljs-number">3</span>,(<span class="hljs-type">CompactBuffer</span>(<span class="hljs-number">4</span>, <span class="hljs-number">6</span>),<span class="hljs-type">CompactBuffer</span>(<span class="hljs-number">9</span>)))

scala&gt; pairs_1.filter{<span class="hljs-keyword">case</span>(x, y) =&gt; y&gt;<span class="hljs-number">4</span>}.collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res40: <span class="hljs-type">String</span> = (<span class="hljs-number">3</span>,<span class="hljs-number">6</span>)
</code></pre>
<h4 id="63-&#x884C;&#x52A8;&#x64CD;&#x4F5C;">6.3 &#x884C;&#x52A8;&#x64CD;&#x4F5C;</h4>
<pre><code class="lang-scala">scala&gt; pairs_1.collect.mkString(<span class="hljs-string">&quot;,&quot;</span>)
res48: <span class="hljs-type">String</span> = (<span class="hljs-number">1</span>,<span class="hljs-number">2</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>),(<span class="hljs-number">3</span>,<span class="hljs-number">6</span>)

## &#x6CE8;&#x610F;&#xFF0C;&#x8FD4;&#x56DE;&#x7684;&#x662F;&#x4E00;&#x4E2A;<span class="hljs-type">Map</span>
scala&gt; pairs_1.countByKey()
res50: scala.collection.<span class="hljs-type">Map</span>[<span class="hljs-type">Int</span>,<span class="hljs-type">Long</span>] = <span class="hljs-type">Map</span>(<span class="hljs-number">1</span> -&gt; <span class="hljs-number">1</span>, <span class="hljs-number">3</span> -&gt; <span class="hljs-number">2</span>)

## &#x6CE8;&#x610F;&#xFF0C;&#x8FD4;&#x56DE;&#x7684;&#x662F;&#x4E00;&#x4E2A;<span class="hljs-type">Map</span>&#xFF0C; &#x4E00;&#x4E2A;<span class="hljs-type">Key</span>&#x5BF9;&#x5E94;&#x4E00;&#x4E2A;<span class="hljs-type">Value</span>
scala&gt; pairs_1.collectAsMap()
res52: scala.collection.<span class="hljs-type">Map</span>[<span class="hljs-type">Int</span>,<span class="hljs-type">Int</span>] = <span class="hljs-type">Map</span>(<span class="hljs-number">1</span> -&gt; <span class="hljs-number">2</span>, <span class="hljs-number">3</span> -&gt; <span class="hljs-number">6</span>)

## &#x67E5;&#x8BE2;<span class="hljs-type">Value</span>
scala&gt; pairs_1.lookup(<span class="hljs-number">3</span>)
res54: <span class="hljs-type">Seq</span>[<span class="hljs-type">Int</span>] = <span class="hljs-type">WrappedArray</span>(<span class="hljs-number">4</span>, <span class="hljs-number">6</span>)

scala&gt; pairs_1.lookup(<span class="hljs-number">3</span>).toString
res55: <span class="hljs-type">String</span> = <span class="hljs-type">WrappedArray</span>(<span class="hljs-number">4</span>, <span class="hljs-number">6</span>)
</code></pre>
<h4 id="64-&#x5206;&#x533A;&#x8BE6;&#x89E3;">6.4 &#x5206;&#x533A;&#x8BE6;&#x89E3;</h4>
<p>&#x6BCF;&#x4E00;&#x4E2A;RDD&#x90FD;&#x662F;&#x4E0D;&#x53EF;&#x53D8;&#x7684;&#xFF0C;&#x6BCF;&#x4E00;&#x4E2A;RDD&#x6211;&#x4EEC;&#x90FD;&#x53EF;&#x4EE5;&#x6307;&#x5B9A;&#x5176;&#x5206;&#x533A;&#x65B9;&#x6CD5;</p>
<ul>
<li>org.apache.spark.HashPartitioner(partitions : scala.Int) Hash&#x5206;&#x533A;</li>
<li>org.apache.spark.RangePartitioner[K, V] &#x8303;&#x56F4;&#x5206;&#x533A;  </li>
</ul>
<p>&#x5206;&#x533A;&#x7684;&#x597D;&#x5904;&#x4E0D;&#x8A00;&#x800C;&#x55BB;&#x2014;&#x2014;&#x51CF;&#x5C11;&#x6570;&#x636E;&#x7684;&#x91CD;&#x65B0;&#x6D17;&#x724C;&#xFF0C;&#x5927;&#x6570;&#x636E;&#x5408;&#x5E76;&#x5C0F;&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x5C0F;&#x6570;&#x636E;&#x5411;&#x7740;&#x5927;&#x6570;&#x636E;&#x96C6;&#x7684;&#x5206;&#x533A;&#x9760;&#x62E2;&#xFF0C;&#x81EA;&#x7136;&#x4E45;&#x7701;&#x53BB;&#x4E86;&#x5F88;&#x591A;&#x7F51;&#x7EDC;&#x7684;&#x8017;&#x65F6;&#xFF0C;&#x4E00;&#x5207;&#x5C31;&#x50CF;&#x662F;&#x5E76;&#x884C;&#x5728;&#x5355;&#x673A;&#x4E0A;&#x4E00;&#x6837;&#x7684;<br>&#x5206;&#x4E00;&#x6B21;&#x5206;&#x533A;&#x90FD;&#x4F1A;&#x521B;&#x5EFA;&#x65B0;&#x7684;RDD<br>&#x5206;&#x533A;&#x5B8C;&#x6BD5;&#x540E;&#x8FD8;&#x9700;&#x8981;&#x7528;&#x5230;&#x5219;&#x9700;&#x8981;&#x4F7F;&#x7528;&#x7F13;&#x5B58;&#x51FD;&#x6570;persist&#xFF0C;&#x907F;&#x514D;&#x6BCF;&#x6B21;&#x90FD;&#x91CD;&#x65B0;&#x5206;&#x533A;</p>
<pre><code class="lang-scala">scala&gt; pairs_1.partitioner
res56: <span class="hljs-type">Option</span>[org.apache.spark.<span class="hljs-type">Partitioner</span>] = <span class="hljs-type">None</span>

scala&gt; pairs_1.partitionBy(<span class="hljs-keyword">new</span> org.apache.spark.<span class="hljs-type">HashPartitioner</span>(<span class="hljs-number">2</span>))
res59: org.apache.spark.rdd.<span class="hljs-type">RDD</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">Int</span>)] = <span class="hljs-type">ShuffledRDD</span>[<span class="hljs-number">42</span>] at partitionBy at &lt;console&gt;:<span class="hljs-number">30</span>

scala&gt; pairs_1.partitioner
res60: <span class="hljs-type">Option</span>[org.apache.spark.<span class="hljs-type">Partitioner</span>] = <span class="hljs-type">None</span>

scala&gt; res59.partitioner
res61: <span class="hljs-type">Option</span>[org.apache.spark.<span class="hljs-type">Partitioner</span>] = <span class="hljs-type">Some</span>(org.apache.spark.<span class="hljs-type">HashPartitioner</span>@<span class="hljs-number">2</span>)

scala&gt; pairs_1.sortByKey()
res62: org.apache.spark.rdd.<span class="hljs-type">RDD</span>[(<span class="hljs-type">Int</span>, <span class="hljs-type">Int</span>)] = <span class="hljs-type">ShuffledRDD</span>[<span class="hljs-number">45</span>] at sortByKey at &lt;console&gt;:<span class="hljs-number">30</span>

scala&gt; res62.partitioner
res63: <span class="hljs-type">Option</span>[org.apache.spark.<span class="hljs-type">Partitioner</span>] = <span class="hljs-type">Some</span>(org.apache.spark.<span class="hljs-type">RangePartitioner</span>@<span class="hljs-number">8</span>ed)
</code></pre>
<p>&#x8FD9;&#x91CC;&#x5217;&#x51FA;&#x4E86;&#x6240;&#x6709;&#x4F1A;&#x4E3A;&#x751F;&#x6210;&#x7684;&#x7ED3;&#x679C; RDD &#x8BBE;&#x597D;&#x5206;&#x533A;&#x65B9;&#x5F0F;&#x7684;&#x64CD;&#x4F5C;&#xFF1A;</p>
<pre><code class="lang-scala">cogroup()
groupWith()
join()
leftOuterJoin()
rightOuterJoin()
groupByKey()
reduceByKey()
combineByKey()
partitionBy()
sort()
mapValues()&#xFF08;&#x5982;&#x679C;&#x7236; <span class="hljs-type">RDD</span> &#x6709;&#x5206;&#x533A;&#x65B9;&#x5F0F;&#x7684;&#x8BDD;&#xFF09;
flatMapValues()&#xFF08;&#x5982;&#x679C;&#x7236; <span class="hljs-type">RDD</span> &#x6709;&#x5206;&#x533A;&#x65B9;&#x5F0F;&#x7684;&#x8BDD;&#xFF09;
filter()&#xFF08;&#x5982;&#x679C;&#x7236; <span class="hljs-type">RDD</span> &#x6709;&#x5206;&#x533A;&#x65B9;&#x5F0F;&#x7684;&#x8BDD;&#xFF09;
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x4E8C;&#x5143;&#x64CD;&#x4F5C;&#xFF0C;&#x8F93;&#x51FA;&#x6570;&#x636E;&#x7684;&#x5206;&#x533A;&#x65B9;&#x5F0F;&#x53D6;&#x51B3;&#x4E8E;&#x7236; RDD &#x7684;&#x5206;&#x533A;&#x65B9;&#x5F0F;&#x3002;&#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x7ED3;&#x679C;&#x4F1A;&#x91C7;&#x7528;&#x54C8;&#x5E0C;&#x5206;&#x533A;&#xFF0C;&#x5206;&#x533A;&#x7684;&#x6570;&#x91CF;&#x548C;&#x64CD;&#x4F5C;&#x7684;&#x5E76;&#x884C;&#x5EA6;&#x4E00;&#x6837;&#x3002;<br>&#x5982;&#x679C;&#x5176;&#x4E2D;&#x7684;&#x4E00;&#x4E2A;&#x7236; RDD &#x5DF2;&#x7ECF;&#x8BBE;&#x7F6E;&#x8FC7;&#x5206;&#x533A;&#x65B9;&#x5F0F;&#xFF0C;&#x90A3;&#x4E48;&#x7ED3;&#x679C;&#x5C31;&#x4F1A;&#x91C7;&#x7528;&#x90A3;&#x79CD;&#x5206;&#x533A;&#x65B9;&#x5F0F;&#xFF1B;<br>&#x5982;&#x679C;&#x4E24;&#x4E2A;&#x7236; RDD &#x90FD;&#x8BBE;&#x7F6E;&#x8FC7;&#x5206;&#x533A;&#x65B9;&#x5F0F;&#xFF0C;&#x7ED3;&#x679C; RDD &#x4F1A;&#x91C7;&#x7528;&#x7B2C;&#x4E00;&#x4E2A;&#x7236; RDD &#x7684;&#x5206;&#x533A;&#x65B9;&#x5F0F;&#x3002;&#x4F46;&#x662F;&#x5206;&#x533A;&#x6570;&#x4F1A;&#x9009;max</p>
<table>
<thead>
<tr>
<th>action</th>
<th>&#x662F;&#x5426;&#x4F1A;&#x4FEE;&#x6539;&#x5206;&#x533A;&#x6570;</th>
<th>&#x662F;&#x5426;&#x4F1A;&#x4FEE;&#x6539;&#x5206;&#x533A;&#x65B9;&#x6CD5;</th>
</tr>
</thead>
<tbody>
<tr>
<td>partitionBy(new HashPartitioner(n))</td>
<td>n</td>
<td>HashPartitioner</td>
</tr>
<tr>
<td>distinct</td>
<td>&#x4E0D;&#x53D8;</td>
<td>none</td>
</tr>
<tr>
<td>distinct(n)</td>
<td>n</td>
<td>none</td>
</tr>
<tr>
<td>mapValues</td>
<td>&#x4E0D;&#x53D8;</td>
<td>&#x4E0D;&#x53D8;</td>
</tr>
<tr>
<td>reduceByKey</td>
<td>&#x4E0D;&#x53D8;</td>
<td>&#x4E0D;&#x53D8;</td>
</tr>
<tr>
<td>map</td>
<td>&#x4E0D;&#x53D8;</td>
<td>none</td>
</tr>
<tr>
<td>zipWithUniqueId</td>
<td>&#x4E0D;&#x53D8;</td>
<td>none</td>
</tr>
</tbody>
</table>
<h3 id="&#x4E03;&#x3001;&#x6587;&#x4EF6;&#x64CD;&#x4F5C;">&#x4E03;&#x3001;&#x6587;&#x4EF6;&#x64CD;&#x4F5C;</h3>
<h4 id="71-spark&#x652F;&#x6301;&#x7684;&#x6587;&#x4EF6;&#x683C;&#x5F0F;">7.1 Spark&#x652F;&#x6301;&#x7684;&#x6587;&#x4EF6;&#x683C;&#x5F0F;</h4>
<table>
<thead>
<tr>
<th>&#x683C;&#x5F0F;&#x540D;&#x79F0;</th>
<th>&#x7ED3;&#x6784;&#x5316;</th>
<th>&#x5907;&#x6CE8;</th>
</tr>
</thead>
<tbody>
<tr>
<td>&#x6587;&#x672C;&#x6587;&#x4EF6;</td>
<td>&#x5426;</td>
<td>&#x666E;&#x901A;&#x7684;&#x6587;&#x672C;&#x6587;&#x4EF6;&#xFF0C;&#x6BCF;&#x884C;&#x4E00;&#x6761;&#x8BB0;&#x5F55;</td>
</tr>
<tr>
<td>JSON</td>
<td>&#x534A;&#x7ED3;&#x6784;&#x5316;</td>
<td>&#x5E38;&#x89C1;&#x7684;&#x57FA;&#x4E8E;&#x6587;&#x672C;&#x7684;&#x683C;&#x5F0F;&#xFF0C;&#x5927;&#x591A;&#x6570;&#x5E93;&#x90FD;&#x8981;&#x6C42;&#x6BCF;&#x884C;&#x4E00;&#x6761;&#x8BB0;&#x5F55;</td>
</tr>
<tr>
<td>CSV</td>
<td>&#x662F;</td>
<td>&#x975E;&#x5E38;&#x5E38;&#x89C1;&#x7684;&#x57FA;&#x4E8E;&#x6587;&#x672C;&#x7684;&#x683C;&#x5F0F;&#xFF0C;&#x901A;&#x5E38;&#x5728;&#x7535;&#x5B50;&#x8868;&#x683C;&#x5E94;&#x7528;&#x4E2D;&#x4F7F;&#x7528;</td>
</tr>
<tr>
<td>SequenceFiles</td>
<td>&#x662F;</td>
<td>&#x4E00;&#x79CD;&#x7528;&#x4E8E;&#x952E;&#x503C;&#x5BF9;&#x6570;&#x636E;&#x7684;&#x5E38;&#x89C1; Hadoop &#x6587;&#x4EF6;&#x683C;&#x5F0F;</td>
</tr>
<tr>
<td>Protocol buffers</td>
<td>&#x662F;</td>
<td>&#x4E00;&#x79CD;&#x5FEB;&#x901F;&#x3001;&#x8282;&#x7EA6;&#x7A7A;&#x95F4;&#x7684;&#x8DE8;&#x8BED;&#x8A00;&#x683C;&#x5F0F;</td>
</tr>
<tr>
<td>&#x5BF9;&#x8C61;&#x6587;&#x4EF6;</td>
<td>&#x662F;</td>
<td>&#x7528;&#x6765;&#x5C06; Spark &#x4F5C;&#x4E1A;&#x4E2D;&#x7684;&#x6570;&#x636E;&#x5B58;&#x50A8;&#x4E0B;&#x6765;&#x4EE5;&#x8BA9;&#x5171;&#x4EAB;&#x7684;&#x4EE3;&#x7801;&#x8BFB;&#x53D6;&#x3002;&#x6539;&#x53D8;&#x7C7B;&#x7684;&#x65F6;&#x5019; &#x5B83;&#x4F1A;&#x5931;&#x6548;&#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x4F9D;&#x8D56;&#x4E8E; Java &#x5E8F;&#x5217;&#x5316;</td>
</tr>
</tbody>
</table>
<pre><code class="lang-scala"># &#x5F53;&#x4F20;&#x5165;&#x7684;&#x53C2;&#x6570;&#x662F;&#x76EE;&#x5F55;&#x7684;&#x65F6;&#x5019;
## &#x8F6C;&#x5316;&#x4E3A;&#x4E00;&#x4E2A;<span class="hljs-type">RDD</span>
<span class="hljs-keyword">val</span> input = sc.textFiles(inputFile)

## &#x8F6C;&#x5316;&#x4E3A;&#x4E00;&#x4E2A;&#x4EE5;&#x6587;&#x4EF6;&#x540D;&#x4E3A;<span class="hljs-type">Key</span>&#x7684;<span class="hljs-type">Pair</span> <span class="hljs-type">RDD</span>
<span class="hljs-keyword">val</span> input = sc.wholeTextFiles(inputFile)

# &#x8F93;&#x51FA;&#x7684;&#x4EA7;&#x51FA;&#x53C2;&#x6570;&#x662F;&#x4E00;&#x4E2A;&#x76EE;&#x5F55;&#xFF0C;&#x56E0;&#x4E3A;<span class="hljs-type">Spark</span>&#x662F;&#x5E76;&#x53D1;&#x8F93;&#x51FA;&#x7684;
rdd.saveAsTextFile(output_path)
</code></pre>
<pre><code class="lang-scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span></span>(args: <span class="hljs-type">Array</span>[<span class="hljs-type">String</span>]) {
    <span class="hljs-keyword">if</span> (args.length &lt; <span class="hljs-number">3</span>) {
        println(<span class="hljs-string">&quot;Usage: [sparkmaster] [inputfile] [outputfile]&quot;</span>)
        exit(<span class="hljs-number">1</span>)
    }
    <span class="hljs-keyword">val</span> master = args(<span class="hljs-number">0</span>)
    <span class="hljs-keyword">val</span> inputFile = args(<span class="hljs-number">1</span>)
    <span class="hljs-keyword">val</span> outputFile = args(<span class="hljs-number">2</span>)
    <span class="hljs-keyword">val</span> sc = <span class="hljs-keyword">new</span> <span class="hljs-type">SparkContext</span>(master, <span class="hljs-string">&quot;BasicParseJson&quot;</span>, <span class="hljs-type">System</span>.getenv(<span class="hljs-string">&quot;SPARK_HOME&quot;</span>))
    <span class="hljs-keyword">val</span> input = sc.textFile(inputFile)
    <span class="hljs-comment">//input.flatMap(msg =&gt; if (JSON.parseObject(msg).getString(&quot;name&quot;).contentEquals(&quot;Sparky The Bear&quot;)) { msg } else { &quot;&quot; }).collect().foreach(print)</span>

    input.map(<span class="hljs-type">JSON</span>.parseObject(_)).saveAsTextFile(outputFile)
}
</code></pre>
<pre><code class="lang-scala"><span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Person</span>(<span class="hljs-params">name: <span class="hljs-type">String</span>, favouriteAnimal: <span class="hljs-type">String</span></span>)</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span></span>(args: <span class="hljs-type">Array</span>[<span class="hljs-type">String</span>]) {
    <span class="hljs-keyword">if</span> (args.length &lt; <span class="hljs-number">3</span>) {
        println(<span class="hljs-string">&quot;Usage: [sparkmaster] [inputfile] [outputfile]&quot;</span>)
        exit(<span class="hljs-number">1</span>)
    }
    <span class="hljs-keyword">val</span> master = args(<span class="hljs-number">0</span>)
    <span class="hljs-keyword">val</span> inputFile = args(<span class="hljs-number">1</span>)
    <span class="hljs-keyword">val</span> outputFile = args(<span class="hljs-number">2</span>)
    <span class="hljs-keyword">val</span> sc = <span class="hljs-keyword">new</span> <span class="hljs-type">SparkContext</span>(master, <span class="hljs-string">&quot;BasicParseCsv&quot;</span>, <span class="hljs-type">System</span>.getenv(<span class="hljs-string">&quot;SPARK_HOME&quot;</span>))
    <span class="hljs-keyword">val</span> input = sc.textFile(inputFile)
    <span class="hljs-keyword">val</span> result = input.map{ line =&gt;
        <span class="hljs-keyword">val</span> reader = <span class="hljs-keyword">new</span> <span class="hljs-type">CSVReader</span>(<span class="hljs-keyword">new</span> <span class="hljs-type">StringReader</span>(line));
        reader.readNext();
    }

    <span class="hljs-keyword">val</span> people = result.map(x =&gt; <span class="hljs-type">Person</span>(x(<span class="hljs-number">0</span>), x(<span class="hljs-number">1</span>)))
    <span class="hljs-keyword">val</span> pandaLovers = people.filter(person =&gt; person.favouriteAnimal == <span class="hljs-string">&quot;panda&quot;</span>)

    pandaLovers.map(person =&gt; <span class="hljs-type">List</span>(person.name, person.favouriteAnimal).toArray).mapPartitions{ people =&gt;
        <span class="hljs-keyword">val</span> stringWriter = <span class="hljs-keyword">new</span> <span class="hljs-type">StringWriter</span>();
        <span class="hljs-keyword">val</span> csvWriter = <span class="hljs-keyword">new</span> <span class="hljs-type">CSVWriter</span>(stringWriter);
        csvWriter.writeAll(people.toList)
        <span class="hljs-type">Iterator</span>(stringWriter.toString)
    }.saveAsTextFile(outputFile)
}
</code></pre>
<h4 id="72-spark&#x652F;&#x6301;&#x7684;&#x6587;&#x4EF6;&#x5B58;&#x50A8;&#x65B9;&#x5F0F;">7.2 Spark&#x652F;&#x6301;&#x7684;&#x6587;&#x4EF6;&#x5B58;&#x50A8;&#x65B9;&#x5F0F;</h4>
<ul>
<li>File System</li>
<li>HDFS</li>
<li>Cassandra</li>
<li>HBase</li>
<li>Amazon S3</li>
<li>Spark SQL</li>
<li>etc. Spark supports text files, SequenceFiles, and any other Hadoop InputFormat.</li>
</ul>
<pre><code class="lang-scala"><span class="hljs-keyword">val</span> lines = sc.textFile(<span class="hljs-string">&quot;file:///usr/local/opt/spark-latest-bin-hadoop2.4/README.md&quot;</span>)  
<span class="hljs-keyword">val</span> lines = sc.textFile(<span class="hljs-string">&quot;hdfs:///usr/local/opt/spark-latest-bin-hadoop2.4/README.md&quot;</span>)  
<span class="hljs-keyword">val</span> lines = sc.textFile(<span class="hljs-string">&quot;s3n://bigdata-east/tmp/README.md&quot;</span>)
</code></pre>
<h3 id="&#x516B;&#x3001;spark&#x7F16;&#x7A0B;&#x8FDB;&#x9636;">&#x516B;&#x3001;Spark&#x7F16;&#x7A0B;&#x8FDB;&#x9636;</h3>
<h4 id="81-&#x5171;&#x4EAB;&#x53D8;&#x91CF;">8.1 &#x5171;&#x4EAB;&#x53D8;&#x91CF;</h4>
<h5 id="811-&#x7D2F;&#x52A0;&#x5668;-accumulator">8.1.1 &#x7D2F;&#x52A0;&#x5668; accumulator</h5>
<ul>
<li>&#x751F;&#x547D;&#x5468;&#x671F;<br>  &#x5728;&#x9A71;&#x52A8;&#x5668;&#x4E2D;&#x521B;&#x5EFA; -- &#x5728;&#x6267;&#x884C;&#x5668;&#x4E2D;&#x7D2F;&#x8BA1; -- &#x5728;&#x9A71;&#x52A8;&#x5668;&#x4E2D;&#x83B7;&#x53D6;&#x8FD4;&#x56DE;&#x7ED3;&#x679C;</li>
<li>&#x7D2F;&#x52A0;&#x5668;&#x4E0D;&#x662F;&#x4E25;&#x683C;&#x7684;&#x53EA;&#x7D2F;&#x8BA1;&#x4E00;&#x6B21;<br>  &#x8F6C;&#x5316;&#x64CD;&#x4F5C;&#x53EF;&#x4EE5;&#x56E0;&#x4E3A;&#x4E00;&#x4E9B;&#x539F;&#x56E0;&#x88AB;&#x591A;&#x6B21;&#x6267;&#x884C;&#xFF08;&#x4EFB;&#x52A1;&#x6267;&#x884C;&#x5931;&#x8D25;&#x91CD;&#x65B0;&#x6267;&#x884C;&#x3001;&#x4EFB;&#x52A1;&#x6267;&#x884C;&#x7684;&#x592A;&#x6162;&#x5457;&#x91CD;&#x65B0;&#x6267;&#x884C;&#x3001;&#x539F;&#x6765;RDD&#x5360;&#x7528;&#x7684;&#x5185;&#x5B58;&#x88AB;&#x56DE;&#x6536;&#x8F6C;&#x5316;&#x64CD;&#x4F5C;&#x91CD;&#x65B0;&#x52A0;&#x8F7D;&#x5E76;&#x6267;&#x884C;&#x65B9;&#x6CD5;&#xFF09;&#xFF0C;&#x4ECE;&#x800C;&#x5BFC;&#x81F4;&#x76EE;&#x524D;&#x7684;&#x7D2F;&#x52A0;&#x5668;&#x53EA;&#x9002;&#x5408;&#x505A;debug&#x4F7F;&#x7528;&#xFF0C;&#x6216;&#x8005;foreach</li>
<li><p>&#x7D2F;&#x52A0;&#x5668;&#x7684;&#x64CD;&#x4F5C;&#x9700;&#x8981;&#x6EE1;&#x8DB3;&#x4EA4;&#x6362;&#x5F8B;(&#x5373;&#xFF0C;a op b&#x7B49;&#x540C;&#x4E8E;b op a) &#x548C; &#x7ED3;&#x5408;&#x5F8B;(&#x5373;&#x3001; (a op b) op c &#x7B49;&#x540C;&#x4E8E; a op (b op c)&#xFF09;&#xFF0C;&#x6BD4;&#x5982;&#x52A0;&#x6CD5;&#x3001;&#x4E58;&#x6CD5;&#x3001;max&#x51FD;&#x6570;</p>
<pre><code class="lang-scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span></span>(args: <span class="hljs-type">Array</span>[<span class="hljs-type">String</span>]) {
  <span class="hljs-keyword">val</span> master = args(<span class="hljs-number">0</span>)
  <span class="hljs-keyword">val</span> inputFile = args(<span class="hljs-number">1</span>)
  <span class="hljs-keyword">val</span> sc = <span class="hljs-keyword">new</span> <span class="hljs-type">SparkContext</span>(master, <span class="hljs-string">&quot;BasicLoadNums&quot;</span>, <span class="hljs-type">System</span>.getenv(<span class="hljs-string">&quot;SPARK_HOME&quot;</span>))
  <span class="hljs-keyword">val</span> file = sc.textFile(inputFile)
  <span class="hljs-keyword">val</span> errorLines = sc.accumulator(<span class="hljs-number">0</span>) <span class="hljs-comment">// Create an Accumulator[Int] initialized to 0</span>
  <span class="hljs-keyword">val</span> dataLines = sc.accumulator(<span class="hljs-number">0</span>) <span class="hljs-comment">// Create a second Accumulator[Int] initialized to 0</span>
  <span class="hljs-keyword">val</span> counts = file.flatMap(line =&gt; {
      <span class="hljs-keyword">try</span> {
          <span class="hljs-keyword">val</span> input = line.split(<span class="hljs-string">&quot; &quot;</span>)
          <span class="hljs-keyword">val</span> data = <span class="hljs-type">Some</span>((input(<span class="hljs-number">0</span>), input(<span class="hljs-number">1</span>).toInt))
          dataLines += <span class="hljs-number">1</span>
          data
      } <span class="hljs-keyword">catch</span> {
          <span class="hljs-keyword">case</span> e: java.lang.<span class="hljs-type">NumberFormatException</span> =&gt; {
              errorLines += <span class="hljs-number">1</span>
              <span class="hljs-type">None</span>
          }
          <span class="hljs-keyword">case</span> e: java.lang.<span class="hljs-type">ArrayIndexOutOfBoundsException</span> =&gt; {
              errorLines += <span class="hljs-number">1</span>
              <span class="hljs-type">None</span>
          }
      }
  }).reduceByKey(_ + _)

  println(counts.collectAsMap().mkString(<span class="hljs-string">&quot;, &quot;</span>))
  println(<span class="hljs-string">s&quot;Too many errors <span class="hljs-subst">${errorLines.value}</span> for <span class="hljs-subst">${dataLines.value}</span>&quot;</span>)
}
</code></pre>
</li>
</ul>
<h5 id="812-&#x5E7F;&#x64AD;&#x53D8;&#x91CF;">8.1.2 &#x5E7F;&#x64AD;&#x53D8;&#x91CF;</h5>
<ul>
<li>&#x8C03;&#x7528;SparkContext.broadcast&#x521B;&#x5EFA;&#x51FA;&#x4E00;&#x4E2A;Broadcast[T]&#x5BF9;&#x8C61;&#x3002; &#x4EFB;&#x4F55;&#x53EF;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x7C7B;&#x578B;&#x90FD;&#x53EF;&#x4EE5;</li>
<li>&#x901A;&#x8FC7;value&#x5C5E;&#x6027;&#x8BBF;&#x95EE;&#x8BE5;&#x5E7F;&#x64AD;&#x53D8;&#x91CF;&#x7684;&#x503C;</li>
<li>&#x5E7F;&#x64AD;&#x53D8;&#x91CF;&#x53EA;&#x4F1A;&#x88AB;&#x53D1;&#x5230;&#x5404;&#x4E2A;&#x8282;&#x70B9;&#x4E00;&#x6B21;&#xFF0C;&#x5E94;&#x4F5C;&#x4E3A;&#x53EA;&#x8BFB;&#x503C;&#x5904;&#x7406;(&#x4F46;&#x662F;&#xFF0C;&#x5982;&#x679C;&#x4FEE;&#x6539;&#x4E86;&#x8FD9;&#x4E2A;&#x503C;&#xFF0C;&#x5C06;&#x4E0D;&#x4F1A;&#x5F71;&#x54CD;&#x5230;&#x522B;&#x7684;&#x8282;&#x70B9;)</li>
<li>&#x4F20;&#x8F93;&#x4E2D;&#x9009;&#x62E9;&#x4E00;&#x4E2A;&#x65E2;&#x597D;&#x53C8;&#x5FEB;&#x7684;&#x5E8F;&#x5217;&#x5316;&#x683C;&#x5F0F;&#x662F;&#x5F88;&#x91CD;&#x8981;&#x7684;</li>
</ul>
<pre><code class="lang-scala"><span class="hljs-keyword">val</span> signPrefixes = sc.broadcast(loadCallSignTable())
<span class="hljs-keyword">val</span> countryContactCounts = contactCounts.map{
    <span class="hljs-keyword">case</span> (sign, count) =&gt;
        <span class="hljs-keyword">val</span> country = lookupInArray(sign, signPrefixes.value)
        (country, count)
}.reduceByKey((x, y) =&gt; x + y)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loadCallSignTable</span></span>() = {
    scala.io.<span class="hljs-type">Source</span>.fromFile(<span class="hljs-string">&quot;./files/callsign_tbl_sorted&quot;</span>).getLines()
        .filter(_ != <span class="hljs-string">&quot;&quot;</span>).toArray
}

# ./files/callsign_tbl_sorted
<span class="hljs-number">3</span>DM, <span class="hljs-type">Swaziland</span> (<span class="hljs-type">Kingdom</span> of)
<span class="hljs-number">3</span>DZ, <span class="hljs-type">Fiji</span> (<span class="hljs-type">Republic</span> of)
<span class="hljs-number">3</span>FZ, <span class="hljs-type">Panama</span> (<span class="hljs-type">Republic</span> of)
<span class="hljs-number">3</span>GZ, <span class="hljs-type">Chile</span>
<span class="hljs-number">3</span>UZ, <span class="hljs-type">China</span> (<span class="hljs-type">People</span><span class="hljs-symbol">&apos;s</span> <span class="hljs-type">Republic</span> of)
</code></pre>
<h4 id="82-&#x8C03;&#x7528;&#x7B2C;&#x4E09;&#x65B9;&#x811A;&#x672C;-pipe">8.2 &#x8C03;&#x7528;&#x7B2C;&#x4E09;&#x65B9;&#x811A;&#x672C; Pipe</h4>
<pre><code class="lang-scala"><span class="hljs-keyword">val</span> pwd = <span class="hljs-type">System</span>.getProperty(<span class="hljs-string">&quot;user.dir&quot;</span>)
<span class="hljs-keyword">val</span> distScript = pwd + <span class="hljs-string">&quot;/bin/finddistance.R&quot;</span>
<span class="hljs-keyword">val</span> distScriptName = <span class="hljs-string">&quot;finddistance.R&quot;</span>
## &#x4E0A;&#x4F20;&#x811A;&#x672C;
sc.addFile(distScript)
<span class="hljs-keyword">val</span> pipeInputs = contactsContactLists.values.flatMap(x =&gt; x.map(y =&gt; <span class="hljs-string">s&quot;<span class="hljs-subst">${y.contactlat}</span>,<span class="hljs-subst">${y.contactlong}</span>,<span class="hljs-subst">${y.mylat}</span>,<span class="hljs-subst">${y.mylong}</span>&quot;</span>))
println(pipeInputs.collect().toList)
## &#x6839;&#x636E;&#x811A;&#x672C;&#x540D;&#x52A0;&#x8F7D;&#x6587;&#x4EF6;
<span class="hljs-keyword">val</span> distances = pipeInputs.pipe(<span class="hljs-type">SparkFiles</span>.get(distScriptName))
</code></pre>
<h4 id="83-&#x6570;&#x503C;rdd---statcounter">8.3 &#x6570;&#x503C;RDD - StatCounter</h4>
<p>&#x8C03;&#x7528;stats()&#x65F6;&#xFF0C;&#x4F1A;&#x901A;&#x8FC7;&#x4E00;&#x6B21;&#x904D;&#x5386;&#x6570;&#x636E;&#x8BA1;&#x7B97;&#x51FA;&#x5927;&#x591A;&#x6570;&#x5E38;&#x7528;&#x7684;&#x6570;&#x636E;&#x7EDF;&#x8BA1;<br>count() RDD &#x4E2D;&#x7684;&#x5143;&#x7D20;&#x4E2A;&#x6570;<br>mean() &#x5143;&#x7D20;&#x7684;&#x5E73;&#x5747;&#x503C;<br>sum() &#x603B;&#x548C;<br>max() &#x6700;&#x5927;&#x503C;<br>min() &#x6700;&#x5C0F;&#x503C;<br>variance() &#x5143;&#x7D20;&#x7684;&#x65B9;&#x5DEE;<br>sampleVariance() &#x4ECE;&#x91C7;&#x6837;&#x4E2D;&#x8BA1;&#x7B97;&#x51FA;&#x7684;&#x65B9;&#x5DEE;<br>stdev() &#x6807;&#x51C6;&#x5DEE;<br>sampleStdev() &#x91C7;&#x6837;&#x7684;&#x6807;&#x51C6;&#x5DEE;</p>
<pre><code class="lang-scala"><span class="hljs-keyword">val</span> stats = distanceDoubles.stats()
<span class="hljs-keyword">val</span> stddev = stats.stdev
<span class="hljs-keyword">val</span> mean = stats.mean
</code></pre>
<blockquote>
<p>@ &#x5B66;&#x5FC5;&#x6C42;&#x5176;&#x5FC3;&#x5F97;&#xFF0C;&#x4E1A;&#x5FC5;&#x8D35;&#x5176;&#x4E13;&#x7CBE;
@ WHAT - HOW - WHY
@ &#x4E0D;&#x79EF;&#x8DEC;&#x6B65; - &#x65E0;&#x4EE5;&#x81F3;&#x5343;&#x91CC; </p>
</blockquote>
<footer class="page-footer"><span class="copyright">Copyright (c) 2019 Tencent PRUCE &amp; KB. all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">time&#xFF1A;
2019-12-01 16:36:53
</span></footer>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../" class="navigation navigation-prev " aria-label="Previous page: Introduction">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="spark_running.html" class="navigation navigation-next " aria-label="Next page: Spark Running">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Spark Quick Start","level":"2.1","depth":1,"next":{"title":"Spark Running","level":"2.2","depth":1,"path":"spark/spark_running.md","ref":"spark/spark_running.md","articles":[]},"previous":{"title":"Introduction","level":"1.1","depth":1,"path":"README.md","ref":"README.md","articles":[]},"dir":"ltr"},"config":{"plugins":["back-to-top-button","splitter","expandable-chapters-small","-sharing","search-pro","tbfed-pagefooter","github","donate","multipart","mathjax","echarts"],"styles":{"website":"./styles/website.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright (c) 2019 Tencent PRUCE & KB.","modify_label":"time：","modify_format":"YYYY-MM-DD HH:mm:ss"},"github":{"url":"https://github.com/prucehuang/bigdata-introduction.git"},"splitter":{},"search-pro":{},"search":{},"multipart":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"donate":{"alipay":"https://github.com/prucehuang/common-resources/blob/master/pictures/zhifubao_pay.jpg?raw=true","alipayText":"支付宝","button":"赏","title":"","wechat":"https://github.com/prucehuang/common-resources/blob/master/pictures/wechat_pay.jpg?raw=true","wechatText":"微信"},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"back-to-top-button":{},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"expandable-chapters-small":{},"echarts":{},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":true},"chart":{}},"theme":"default","author":"pruce","pdf":{"pageNumbers":true,"fontSize":16,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"bigdata-introduction","language":"zh-hans","gitbook":"3.2.3","description":"bigdata notes"},"file":{"path":"spark/spark_quick_start.md","mtime":"2019-12-01T08:36:53.417Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-12-01T09:30:28.029Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-donate/plugin.js"></script>
        
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

